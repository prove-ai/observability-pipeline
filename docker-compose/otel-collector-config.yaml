receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
  prometheus:
    config:
      scrape_configs:
        - job_name: "vllm-native-metrics"
          scrape_interval: 15s
          static_configs:
            - targets: ["host.docker.internal:8000"] # add vllm server target
          metric_relabel_configs:
            # add consistent labeling to vllm metrics
            - source_labels: [__name__]
              target_label: source
              replacement: "vllm"

processors:
  batch: {}
  attributes:
    actions:
      - key: instrumentation_source
        value: vllm
        action: insert

connectors:
  spanmetrics:
    histogram:
      explicit:
        buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]
    dimensions:
      - name: env
      - name: component
    dimensions_cache_size: 1000

exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: llm
    resource_to_telemetry_conversion:
      enabled: true
    enable_open_metrics: true
  debug:
    verbosity: detailed

extensions:
  health_check:
    endpoint: 0.0.0.0:13133

service:
  extensions: [health_check]
  telemetry:
    metrics:
      level: detailed
      readers:
        - pull:
            exporter:
              prometheus:
                host: 0.0.0.0
                port: 8888
    logs:
      level: debug
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [spanmetrics, debug] # Send to spanmetrics connector
    metrics:
      receivers: [otlp, spanmetrics] # Receive from OTLP and spanmetrics
      processors: [batch]
      exporters: [prometheus, debug]
